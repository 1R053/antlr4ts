/*
 * [The "BSD license"]
 *  Copyright (c) 2012 Terence Parr
 *  Copyright (c) 2012 Sam Harwell
 *  All rights reserved.
 *
 *  Redistribution and use in source and binary forms, with or without
 *  modification, are permitted provided that the following conditions
 *  are met:
 *
 *  1. Redistributions of source code must retain the above copyright
 *     notice, this list of conditions and the following disclaimer.
 *  2. Redistributions in binary form must reproduce the above copyright
 *     notice, this list of conditions and the following disclaimer in the
 *     documentation and/or other materials provided with the distribution.
 *  3. The name of the author may not be used to endorse or promote products
 *     derived from this software without specific prior written permission.
 *
 *  THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR
 *  IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES
 *  OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.
 *  IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,
 *  INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT
 *  NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
 *  DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
 *  THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
 *  (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF
 *  THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 */

// ConvertTo-TS run at 2016-10-04T11:27:04.9040731-07:00

// import org.junit.Test;

// import static org.junit.Assert.*;

/**
 * Lexer rules are little quirky when it comes to wildcards. Problem
 * stems from the fact that we want the longest match to win among
 * several rules and even within a rule. However, that conflicts
 * with the notion of non-greedy, which by definition tries to match
 * the fewest possible. During ATN construction, non-greedy loops
 * have their entry and exit branches reversed so that the ATN
 * simulator will see the exit branch 1st, giving it a priority. The
 * 1st path to the stop state kills any other paths for that rule
 * that begin with the wildcard. In general, this does everything we
 * want, but occasionally there are some quirks as you'll see from
 * the tests below.
 */
export class TestATNLexerInterpreter extends BaseTest {
	@Test testLexerTwoRules(): void {
		let lg: LexerGrammar =  new LexerGrammar(
			"lexer grammar L;\n"+
			"A : 'a' ;\n" +
			"B : 'b' ;\n");
		let expecting: string =  "A, B, A, B, EOF";
		checkLexerMatches(lg, "abab", expecting);
	}

	@Test testShortLongRule(): void {
		let lg: LexerGrammar =  new LexerGrammar(
			"lexer grammar L;\n"+
			"A : 'xy'\n" +
			"  | 'xyz'\n" + // this alt is preferred since there are no non-greedy configs
			"  ;\n" +
			"Z : 'z'\n" +
			"  ;\n");
		checkLexerMatches(lg, "xy", "A, EOF");
		checkLexerMatches(lg, "xyz", "A, EOF");
	}

	@Test testShortLongRule2(): void {
		let lg: LexerGrammar =  new LexerGrammar(
			"lexer grammar L;\n"+
			"A : 'xyz'\n" +  // make sure nongreedy mech cut off doesn't kill this alt
			"  | 'xy'\n" +
			"  ;\n");
		checkLexerMatches(lg, "xy", "A, EOF");
		checkLexerMatches(lg, "xyz", "A, EOF");
	}

	@Test testWildOnEndFirstAlt(): void {
		let lg: LexerGrammar =  new LexerGrammar(
			"lexer grammar L;\n"+
			"A : 'xy' .\n" + // should pursue '.' since xyz hits stop first, before 2nd alt
			"  | 'xy'\n" +
			"  ;\n" +
			"Z : 'z'\n" +
			"  ;\n");
		checkLexerMatches(lg, "xy", "A, EOF");
		checkLexerMatches(lg, "xyz", "A, EOF");
	}

	@Test testWildOnEndLastAlt(): void {
		let lg: LexerGrammar =  new LexerGrammar(
			"lexer grammar L;\n"+
			"A : 'xy'\n" +
			"  | 'xy' .\n" +  // this alt is preferred since there are no non-greedy configs
			"  ;\n" +
			"Z : 'z'\n" +
			"  ;\n");
		checkLexerMatches(lg, "xy", "A, EOF");
		checkLexerMatches(lg, "xyz", "A, EOF");
	}

	@Test testWildcardNonQuirkWhenSplitBetweenTwoRules(): void {
		let lg: LexerGrammar =  new LexerGrammar(
			"lexer grammar L;\n"+
			"A : 'xy' ;\n" +
			"B : 'xy' . 'z' ;\n");
		checkLexerMatches(lg, "xy", "A, EOF");
		checkLexerMatches(lg, "xyqz", "B, EOF");
	}

	@Test testLexerLoops(): void {
		let lg: LexerGrammar =  new LexerGrammar(
			"lexer grammar L;\n"+
			"INT : '0'..'9'+ ;\n" +
			"ID : 'a'..'z'+ ;\n");
		let expecting: string =  "ID, INT, ID, INT, EOF";
		checkLexerMatches(lg, "a34bde3", expecting);
	}

	@Test testLexerNotSet(): void {
		let lg: LexerGrammar =  new LexerGrammar(
			"lexer grammar L;\n"+
			"ID : ~('a'|'b')\n ;");
		let expecting: string =  "ID, EOF";
		checkLexerMatches(lg, "c", expecting);
	}

	@Test testLexerKeywordIDAmbiguity(): void {
		let lg: LexerGrammar =  new LexerGrammar(
			"lexer grammar L;\n"+
			"KEND : 'end' ;\n" +
			"ID : 'a'..'z'+ ;\n" +
			"WS : (' '|'\\n')+ ;");
		let expecting: string =  "ID, EOF";
		//checkLexerMatches(lg, "e", expecting);
		expecting = "KEND, EOF";
		checkLexerMatches(lg, "end", expecting);
		expecting = "ID, EOF";
		checkLexerMatches(lg, "ending", expecting);
		expecting = "ID, WS, KEND, WS, ID, EOF";
		checkLexerMatches(lg, "a end bcd", expecting);
	}

	@Test testLexerRuleRef(): void {
		let lg: LexerGrammar =  new LexerGrammar(
			"lexer grammar L;\n"+
			"INT : DIGIT+ ;\n" +
			"fragment DIGIT : '0'..'9' ;\n" +
			"WS : (' '|'\\n')+ ;");
		let expecting: string =  "INT, WS, INT, EOF";
		checkLexerMatches(lg, "32 99", expecting);
	}

	@Test testRecursiveLexerRuleRef(): void {
		let lg: LexerGrammar =  new LexerGrammar(
			"lexer grammar L;\n"+
			"CMT : '/*' (CMT | ~'*')+ '*/' ;\n" +
			"WS : (' '|'\\n')+ ;");
		let expecting: string =  "CMT, WS, CMT, EOF";
		checkLexerMatches(lg, "/* ick */\n/* /*nested*/ */", expecting);
	}

	@Test testRecursiveLexerRuleRefWithWildcard(): void {
		let lg: LexerGrammar =  new LexerGrammar(
			"lexer grammar L;\n"+
			"CMT : '/*' (CMT | .)*? '*/' ;\n" +
			"WS : (' '|'\\n')+ ;");

		let expecting: string =  "CMT, WS, CMT, WS, EOF";
		checkLexerMatches(lg,
						  "/* ick */\n" +
						  "/* /* */\n" +
						  "/* /*nested*/ */\n",
						  expecting);
	}

	@Test testLexerWildcardGreedyLoopByDefault(): void {
		let lg: LexerGrammar =  new LexerGrammar(
			"lexer grammar L;\n"+
			"CMT : '//' .* '\\n' ;\n");
		let expecting: string =  "CMT, EOF";
		checkLexerMatches(lg, "//x\n//y\n", expecting);
	}

	@Test testLexerWildcardLoopExplicitNonGreedy(): void {
		let lg: LexerGrammar =  new LexerGrammar(
			"lexer grammar L;\n"+
			"CMT : '//' .*? '\\n' ;\n");
		let expecting: string =  "CMT, CMT, EOF";
		checkLexerMatches(lg, "//x\n//y\n", expecting);
	}

	@Test testLexerEscapeInString(): void {
		let lg: LexerGrammar =  new LexerGrammar(
			"lexer grammar L;\n"+
			"STR : '[' ('~' ']' | .)* ']' ;\n");
		checkLexerMatches(lg, "[a~]b]", "STR, EOF");
		checkLexerMatches(lg, "[a]", "STR, EOF");
	}

	@Test testLexerWildcardGreedyPlusLoopByDefault(): void {
		let lg: LexerGrammar =  new LexerGrammar(
			"lexer grammar L;\n"+
			"CMT : '//' .+ '\\n' ;\n");
		let expecting: string =  "CMT, EOF";
		checkLexerMatches(lg, "//x\n//y\n", expecting);
	}

	@Test testLexerWildcardExplicitNonGreedyPlusLoop(): void {
		let lg: LexerGrammar =  new LexerGrammar(
			"lexer grammar L;\n"+
			"CMT : '//' .+? '\\n' ;\n");
		let expecting: string =  "CMT, CMT, EOF";
		checkLexerMatches(lg, "//x\n//y\n", expecting);
	}

	// does not fail since ('*/')? can't match and have rule succeed
	@Test testLexerGreedyOptionalShouldWorkAsWeExpect(): void {
		let lg: LexerGrammar =  new LexerGrammar(
			"lexer grammar L;\n"+
			"CMT : '/*' ('*/')? '*/' ;\n");
		let expecting: string =  "CMT, EOF";
		checkLexerMatches(lg, "/**/", expecting);
	}

	@Test testGreedyBetweenRules(): void {
		let lg: LexerGrammar =  new LexerGrammar(
			"lexer grammar L;\n"+
			"A : '<a>' ;\n" +
			"B : '<' .+ '>' ;\n");
		let expecting: string =  "B, EOF";
		checkLexerMatches(lg, "<a><x>", expecting);
	}

	@Test testNonGreedyBetweenRules(): void {
		let lg: LexerGrammar =  new LexerGrammar(
			"lexer grammar L;\n"+
			"A : '<a>' ;\n" +
			"B : '<' .+? '>' ;\n");
		let expecting: string =  "A, B, EOF";
		checkLexerMatches(lg, "<a><x>", expecting);
	}

	@Test testEOFAtEndOfLineComment(): void {
		let lg: LexerGrammar =  new LexerGrammar(
			"lexer grammar L;\n"+
			"CMT : '//' ~('\\n')* ;\n");
		let expecting: string =  "CMT, EOF";
		checkLexerMatches(lg, "//x", expecting);
	}

	@Test testEOFAtEndOfLineComment2(): void {
		let lg: LexerGrammar =  new LexerGrammar(
			"lexer grammar L;\n"+
			"CMT : '//' ~('\\n'|'\\r')* ;\n");
		let expecting: string =  "CMT, EOF";
		checkLexerMatches(lg, "//x", expecting);
	}

	/** only positive sets like (EOF|'\n') can match EOF and not in wildcard or ~foo sets
	 *  EOF matches but does not advance cursor.
	 */
	@Test testEOFInSetAtEndOfLineComment(): void {
		let lg: LexerGrammar =  new LexerGrammar(
			"lexer grammar L;\n"+
			"CMT : '//' .* (EOF|'\\n') ;\n");
		let expecting: string =  "CMT, EOF";
		checkLexerMatches(lg, "//", expecting);
	}

	@Test testEOFSuffixInSecondRule(): void {
		let lg: LexerGrammar =  new LexerGrammar(
			"lexer grammar L;\n"+
			"A : 'a' ;\n"+ // shorter than 'a' EOF, despite EOF being 0 width
			"B : 'a' EOF ;\n");
		let expecting: string =  "B, EOF";
		checkLexerMatches(lg, "a", expecting);
	}

	@Test testEOFSuffixInFirstRule(): void {
		let lg: LexerGrammar =  new LexerGrammar(
			"lexer grammar L;\n"+
			"A : 'a' EOF ;\n"+
			"B : 'a';\n");
		let expecting: string =  "A, EOF";
		checkLexerMatches(lg, "a", expecting);
	}

	@Test testEOFByItself(): void {
		let lg: LexerGrammar =  new LexerGrammar(
			"lexer grammar L;\n"+
			"DONE : EOF ;\n"+
			"A : 'a';\n");
		let expecting: string =  "A, DONE, EOF";
		checkLexerMatches(lg, "a", expecting);
	}

	protected checkLexerMatches(lg: LexerGrammar, inputString: string, expecting: string): void {
		let atn: ATN =  createATN(lg, true);
		let input: CharStream =  new ANTLRInputStream(inputString);
		let startState: ATNState =  atn.modeNameToStartState.get("DEFAULT_MODE");
		let dot: DOTGenerator =  new DOTGenerator(lg);
		console.log(dot.getDOT(startState, true));

		let tokenTypes: List<string> =  getTokenTypes(lg, atn, input);

		let result: string =  Utils.join(tokenTypes.iterator(), ", ");
		console.log(tokenTypes);
		assertEquals(expecting, result);
	}

}
